{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "#always start creating the session\n",
    "#we should always start wuth session in order to obtain\n",
    "#context and session if needed\n",
    "\n",
    "\n",
    "#connection to spark to s3\n",
    "cfg = (pyspark.SparkConf()\n",
    " # Setting where master node is located [cores for multiprocessing]\n",
    ".setMaster(f\"local[{multiprocessing.cpu_count()}]\") \n",
    " # Setting application name \n",
    " .setAppName(\"PinterestDataApp\") \n",
    " # Setting config value via string \n",
    " .set(\"spark.eventLog.enabled\", False) \n",
    " .set(\"fs.s3a.access.key\", \"AKIA5V4FQSSRSAYSHBCP\") \n",
    " .set(\"fs.s3a.secret.key\", \"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\") \n",
    " .set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\") \n",
    " # Setting environment variables for executors to use \n",
    " .setExecutorEnv(pairs=[(\"VAR3\", \"value3\"), (\"VAR4\", \"value4\")]) \n",
    " # Setting memory if this setting was not set previously \n",
    " .setIfMissing(\"spark.executor.memory\", \"1g\") ) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/31 19:41:27 WARN Utils: Your hostname, ed-NL40-50GU resolves to a loopback address: 127.0.1.1; using 192.168.1.104 instead (on interface wlp2s0)\n",
      "22/05/31 19:41:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ed/Programs/spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ed/Programs/spark-3.2.1-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ed/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ed/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector-assembly_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-68849234-885c-4cc6-bc1f-ef0988e7b846;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.2.0 in central\n",
      ":: resolution report :: resolve 499ms :: artifacts dl 22ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.spark#spark-cassandra-connector-assembly_2.12;3.2.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-68849234-885c-4cc6-bc1f-ef0988e7b846\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/8ms)\n",
      "22/05/31 19:41:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Exception in thread \"main\" org.apache.spark.SparkException: Failed to get main class in JAR with error 'File file:/home/ed/Work/Packages/Pinterest_data_pipeline/API/spark_to_s3.ipynb does not exist'.  Please specify one with --class.\n",
      "\tat org.apache.spark.deploy.SparkSubmit.error(SparkSubmit.scala:972)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:486)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:898)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1043)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1052)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ed/Work/Packages/Pinterest_data_pipeline/API/s3_to_spark.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ed/Work/Packages/Pinterest_data_pipeline/API/s3_to_spark.ipynb#ch0000002?line=4'>5</a>\u001b[0m \u001b[39m# Adding the packages required to get data from S3  \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ed/Work/Packages/Pinterest_data_pipeline/API/s3_to_spark.ipynb#ch0000002?line=5'>6</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mPYSPARK_SUBMIT_ARGS\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m--packages com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.2.0 spark_to_s3.ipynb pyspark-shell\u001b[39m\u001b[39m'\u001b[39m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ed/Work/Packages/Pinterest_data_pipeline/API/s3_to_spark.ipynb#ch0000002?line=6'>7</a>\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mmaster(\u001b[39m\"\u001b[39;49m\u001b[39mlocal\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mappName(\u001b[39m\"\u001b[39;49m\u001b[39mtestapp\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mgetOrCreate() \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ed/Work/Packages/Pinterest_data_pipeline/API/s3_to_spark.ipynb#ch0000002?line=7'>8</a>\u001b[0m sc \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39msparkContext\n",
      "File \u001b[0;32m~/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/sql/session.py:228\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/sql/session.py?line=225'>226</a>\u001b[0m         sparkConf\u001b[39m.\u001b[39mset(key, value)\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/sql/session.py?line=226'>227</a>\u001b[0m     \u001b[39m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/sql/session.py?line=227'>228</a>\u001b[0m     sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39;49mgetOrCreate(sparkConf)\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/sql/session.py?line=228'>229</a>\u001b[0m \u001b[39m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/sql/session.py?line=229'>230</a>\u001b[0m \u001b[39m# by all sessions.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/sql/session.py?line=230'>231</a>\u001b[0m session \u001b[39m=\u001b[39m SparkSession(sc)\n",
      "File \u001b[0;32m~/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py:392\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=389'>390</a>\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=390'>391</a>\u001b[0m     \u001b[39mif\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=391'>392</a>\u001b[0m         SparkContext(conf\u001b[39m=\u001b[39;49mconf \u001b[39mor\u001b[39;49;00m SparkConf())\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=392'>393</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py:144\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=138'>139</a>\u001b[0m \u001b[39mif\u001b[39;00m gateway \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m gateway\u001b[39m.\u001b[39mgateway_parameters\u001b[39m.\u001b[39mauth_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=139'>140</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=140'>141</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=141'>142</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not allowed as it is a security risk.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=143'>144</a>\u001b[0m SparkContext\u001b[39m.\u001b[39;49m_ensure_initialized(\u001b[39mself\u001b[39;49m, gateway\u001b[39m=\u001b[39;49mgateway, conf\u001b[39m=\u001b[39;49mconf)\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=144'>145</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=146'>147</a>\u001b[0m                   conf, jsc, profiler_cls)\n",
      "File \u001b[0;32m~/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py:339\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=336'>337</a>\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=337'>338</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_gateway:\n\u001b[0;32m--> <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=338'>339</a>\u001b[0m         SparkContext\u001b[39m.\u001b[39m_gateway \u001b[39m=\u001b[39m gateway \u001b[39mor\u001b[39;00m launch_gateway(conf)\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=339'>340</a>\u001b[0m         SparkContext\u001b[39m.\u001b[39m_jvm \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_gateway\u001b[39m.\u001b[39mjvm\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/context.py?line=341'>342</a>\u001b[0m     \u001b[39mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m~/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/java_gateway.py:108\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/java_gateway.py?line=104'>105</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/java_gateway.py?line=106'>107</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m--> <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/java_gateway.py?line=107'>108</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava gateway process exited before sending its port number\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/java_gateway.py?line=109'>110</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(conn_info_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m info:\n\u001b[1;32m    <a href='file:///home/ed/miniconda3/envs/AiCore/lib/python3.9/site-packages/pyspark/java_gateway.py?line=110'>111</a>\u001b[0m     gateway_port \u001b[39m=\u001b[39m read_int(info)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3') \n",
    "bucket = s3.Bucket('pin-api') \n",
    "# Adding the packages required to get data from S3  \n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.2.0 s3_to_spark.ipynb pyspark-shell' \n",
    "spark = SparkSession.builder.master(\"local\").appName(\"testapp\").getOrCreate() \n",
    "sc = spark.sparkContext \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchKey",
     "evalue": "An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/bianca/New Volume/Pinterest_App/API/s3_to_spark.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/bianca/New%20Volume/Pinterest_App/API/s3_to_spark.ipynb#ch0000003?line=2'>3</a>\u001b[0m json_list \u001b[39m=\u001b[39m [] \n\u001b[1;32m      <a href='vscode-notebook-cell:/media/bianca/New%20Volume/Pinterest_App/API/s3_to_spark.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m): \n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/bianca/New%20Volume/Pinterest_App/API/s3_to_spark.ipynb#ch0000003?line=4'>5</a>\u001b[0m     obj \u001b[39m=\u001b[39m s3\u001b[39m.\u001b[39;49mObject(bucket_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpin-api\u001b[39;49m\u001b[39m'\u001b[39;49m, key\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAPI_data\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mget() \n\u001b[1;32m      <a href='vscode-notebook-cell:/media/bianca/New%20Volume/Pinterest_App/API/s3_to_spark.ipynb#ch0000003?line=5'>6</a>\u001b[0m     obj_string_to_json \u001b[39m=\u001b[39m obj[\u001b[39m\"\u001b[39m\u001b[39mBody\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[1;32m      <a href='vscode-notebook-cell:/media/bianca/New%20Volume/Pinterest_App/API/s3_to_spark.ipynb#ch0000003?line=6'>7</a>\u001b[0m     data \u001b[39m=\u001b[39m dumps(obj_string_to_json)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mrstrip(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mlstrip(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m) \n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py:580\u001b[0m, in \u001b[0;36mResourceFactory._create_action.<locals>.do_action\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py?line=578'>579</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_action\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py?line=579'>580</a>\u001b[0m     response \u001b[39m=\u001b[39m action(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py?line=581'>582</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mload\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py?line=582'>583</a>\u001b[0m         \u001b[39m# Clear cached data. It will be reloaded the next\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py?line=583'>584</a>\u001b[0m         \u001b[39m# time that an attribute is accessed.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py?line=584'>585</a>\u001b[0m         \u001b[39m# TODO: Make this configurable in the future?\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py?line=585'>586</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py:88\u001b[0m, in \u001b[0;36mServiceAction.__call__\u001b[0;34m(self, parent, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=78'>79</a>\u001b[0m params\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=80'>81</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=81'>82</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mCalling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=82'>83</a>\u001b[0m     parent\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mservice_name,\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=83'>84</a>\u001b[0m     operation_name,\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=84'>85</a>\u001b[0m     params,\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=85'>86</a>\u001b[0m )\n\u001b[0;32m---> <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=87'>88</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(parent\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mclient, operation_name)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=89'>90</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mResponse: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m, response)\n\u001b[1;32m     <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py?line=91'>92</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_handler(parent, params, response)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/botocore/client.py:508\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=503'>504</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=504'>505</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=505'>506</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=506'>507</a>\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=507'>508</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/botocore/client.py:911\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=908'>909</a>\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=909'>910</a>\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=910'>911</a>\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=911'>912</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/bianca/miniconda3/lib/python3.9/site-packages/botocore/client.py?line=912'>913</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist."
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "json_list = [] \n",
    "for i in range(10): \n",
    "    obj = s3.Object(bucket_name='pin-api').get() \n",
    "    obj_string_to_json = obj[\"Body\"].read().decode('utf-8') \n",
    "    data = dumps(obj_string_to_json).replace(\"'\", '\"').rstrip('\"').lstrip('\"') \n",
    "    json_list.append(data) \n",
    "df = spark.read.option(\"mode\", \"PERMISSIVE\").option(\"columnNameOfCorruptRecord\", \"_corrupt_record\").json(sc.parallelize())\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fc064e61596ecd42e42d4956267622470104d1bed4e5c08f86c42ab04a1e67f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('AiCore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
